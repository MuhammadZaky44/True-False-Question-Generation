# -*- coding: utf-8 -*-
"""Coordination Modification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qkx_AssYngF-vht_lJ47s00LaebUDEmB
"""

# from google.colab import drive
# drive.mount('/content/gdrive')
# !cp '/content/gdrive/My Drive/Tugas_Akhir/all_indo_man_tag_corpus_model.crf.tagger' all_indo_man_tag_corpus_model.crf.tagger

# !pip install python-crfsuite
import nltk
nltk.download('punkt')
from nltk import word_tokenize
from nltk.tag import CRFTagger
import random

"""# Preprocessing"""

def preprocessing(text):
    tokenized = word_tokenize(text)
    return tokenized

sentence = 'Andi dan Budi sedang bermain bola dan pasir di pantai'
sentences = sentence.split('. ')

tokenized_sentences = []
tagged_sentences = []


for sentence in sentences:
    tokens = preprocessing(sentence)
    tokenized_sentences.append(tokens)
    ct = CRFTagger()
    ct.set_model_file('files/all_indo_man_tag_corpus_model.crf.tagger')
    tagged_sentence = ct.tag(tokens)
    tagged_sentences.append(tagged_sentence)

for i in range(len(tokenized_sentences)):
    print(tokenized_sentences[i])
    print("\n")

for i in range(len(tagged_sentences)):
  print(tagged_sentences[i])
  print("\n")

for i in range(len(tagged_sentences)):
    tokens = tagged_sentences[i]
    j = 0
    while j < len(tokens) - 2:
        if tokens[j][1].startswith('N') and tokens[j+1][1] == 'CC' and tokens[j+2][1].startswith('N'):
            del tokens[j]
            del tokens[j]
        j += 1
    tagged_sentences[i] = tokens
    modified_sentence = ' '.join([t[0] for t in tokens])
    print(modified_sentence)
    print("\n")